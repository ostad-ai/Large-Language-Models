# Large Language Models (LLMs)
(under construction)
1) <a href="./what is an LLM.ipynb">What is a Large Language Model (LMM)?</a>
2) <a href="./what is the building block of an LLM.ipynb">What is the building block of an LLM?</a>
3) **LLMs, self-attention mechanism:** The self-attention mechanism is the core concept of **transformer**-based LLMs. Here, we review the formulae of this mechanism and implement a self-attention from scratch in Python.
4) **LLMs, the softmax in self-attention:** We remind the softmax function ,which is widely used in *neural networks*, *deep learning*, and *machine learning*. The function softmax is implemented in Python with an example.